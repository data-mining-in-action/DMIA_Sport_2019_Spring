{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv.gz', compression='gzip')\n",
    "train = train.drop(train[train.price == 0].index)\n",
    "\n",
    "test = pd.read_csv('data/test.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# кросс-валидация\n",
    "test['price'] = -1\n",
    "\n",
    "data = pd.concat([train, test], 0) #, sort=False)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "def cv_mode(CV):\n",
    "    \n",
    "    if CV:\n",
    "    \n",
    "        cv = KFold(n_splits=5, shuffle=False, random_state=42).split(data.iloc[:train.shape[0]])\n",
    "    \n",
    "    else:\n",
    "        i_tr = data.iloc[:train.shape[0]].index\n",
    "        i_tst = data.iloc[train.shape[0]:].index\n",
    "        cv = (i_tr, i_tst)\n",
    "    \n",
    "    return cv\n",
    "\n",
    "def make_prediction( model, X, y, i_tr, i_tst):\n",
    "    X_train, X_test = X.iloc[i_tr, :], X.iloc[i_tst, :]\n",
    "    y_train, y_test = np.log1p(y.iloc[i_tr]), y.iloc[i_tst]\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = np.expm1(model.predict(X_test))\n",
    "    return prediction, MAPE(y_test, prediction)\n",
    "        \n",
    "    \n",
    "def cross_val(model, X, y, CV=True):\n",
    "    cv = cv_mode(CV)\n",
    "    scores = []\n",
    "    for i_tr, i_tst in cv:\n",
    "        _, score = make_prediction(model, X, y, i_tr, i_tst)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "\n",
    "def make_subm(model, X, y, filename, CV=False):\n",
    "    cv = cv_mode(CV)\n",
    "    (i_tr, i_tst) = cv\n",
    "    prediction, _ = make_prediction(model, X, y, i_tr, i_tst)\n",
    "    subm['price'] = prediction\n",
    "    subm.to_csv(filename, index=False)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bed_type                                5\n",
       "cancellation_policy                     6\n",
       "host_has_profile_pic                    2\n",
       "host_identity_verified                  2\n",
       "host_is_superhost                       2\n",
       "host_response_time                      4\n",
       "is_location_exact                       2\n",
       "neighbourhood_cleansed                 33\n",
       "property_type                          40\n",
       "require_guest_phone_verification        2\n",
       "require_guest_profile_picture           2\n",
       "room_type                               3\n",
       "zipcode                             23648\n",
       "host_id                             32597\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Какой признак лучше выбрать для targetencoding?\n",
    "\n",
    "num_cols = ['accommodates', 'bathrooms', 'bedrooms', 'beds', 'square_feet',\n",
    "            'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people',\n",
    "            'minimum_nights', 'latitude', 'longitude']\n",
    "\n",
    "cat_cols = ['bed_type', 'cancellation_policy', 'host_has_profile_pic', 'host_identity_verified', \n",
    "            'host_is_superhost', 'host_response_time', 'is_location_exact', 'neighbourhood_cleansed',\n",
    "            'property_type', 'require_guest_phone_verification', 'require_guest_profile_picture',\n",
    "            'room_type', 'zipcode', 'host_id']\n",
    "\n",
    "train[cat_cols].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# возьмем neighbourhood_cleansed, 'property_type' и zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Подготовим датасет для экспериментов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# разобьем на обучение и валидацию\n",
    "\n",
    "X = train[num_cols + ['neighbourhood_cleansed', 'zipcode', 'property_type']]\n",
    "y = train.price\n",
    "\n",
    "for col in ['neighbourhood_cleansed', 'zipcode', 'property_type']:\n",
    "    X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MAPE(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true-y_pred) / (y_true)).replace([-np.inf, np.inf], np.nan).dropna())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rate(X_train, X_test):\n",
    "    model = LGBMRegressor()\n",
    "    model.fit(X_train, np.log1p(y_train))\n",
    "    preds = np.expm1(model.predict(X_test))\n",
    "    return MAPE(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.687587710683623"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество без категориальных признаков\n",
    "get_rate(X_train.drop(['neighbourhood_cleansed', 'zipcode', 'property_type'], axis=1),\n",
    "         X_test.drop(['neighbourhood_cleansed', 'zipcode', 'property_type'], axis=1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.510956016192566"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество с категориальными признаками, закодированными LabelEncoding\n",
    "get_rate(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.43596338287703"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Качество с ['neighbourhood_cleansed', 'property_type'], закодированными OneHotEncoding\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "get_rate(np.hstack((X_train.drop(['neighbourhood_cleansed', 'property_type'], axis=1), \n",
    "                    ohe.fit_transform(X_train[['neighbourhood_cleansed', 'property_type']]))),\n",
    "         np.hstack((X_test.drop(['neighbourhood_cleansed', 'property_type'], axis=1), \n",
    "                    ohe.transform(X_test[['neighbourhood_cleansed', 'property_type']])))\n",
    ")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Чем кодируем? средним по таргету или по логарифму таргета? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train[num_cols + ['neighbourhood_cleansed', 'zipcode', 'property_type']]\n",
    "y = train.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.05249907563195"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in ['neighbourhood_cleansed', 'property_type', 'zipcode']:\n",
    "    tmp = pd.DataFrame({'feature': X_train[col], 'target': np.log1p(y_train)}).dropna()\n",
    "    global_mean = y_train.mean()\n",
    "    mean = tmp.groupby('feature').target.mean()\n",
    "    X_train[col + '_te'] = X_train[col].map(mean).fillna(global_mean).values\n",
    "    X_test[col + '_te'] = X_test[col].map(mean).fillna(global_mean).values\n",
    "    \n",
    "# Смотрим качество\n",
    "get_rate(X_train.drop(['neighbourhood_cleansed', 'zipcode','property_type'], axis=1),\n",
    "         X_test.drop(['neighbourhood_cleansed', 'zipcode','property_type'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.99903566366023"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Добавим сглаживание\n",
    "\n",
    "C = 10\n",
    "\n",
    "for col in ['neighbourhood_cleansed', 'zipcode', 'property_type']:\n",
    "    tmp = pd.DataFrame({'feature': X_train[col], 'target': np.log1p(y_train)}).dropna()\n",
    "    global_mean = y_train.mean()\n",
    "    mean = tmp.groupby('feature').target.mean()\n",
    "    size = tmp.groupby('feature').target.size()\n",
    "    encoding = (global_mean * C + mean * size) / (C + size)\n",
    "    X_train[col + '_te'] = X_train[col].map(encoding).fillna(global_mean).values\n",
    "    X_test[col + '_te'] = X_test[col].map(encoding).fillna(global_mean).values\n",
    "    \n",
    "# качество\n",
    "get_rate(X_train.drop(['neighbourhood_cleansed', 'zipcode', 'property_type'], axis=1),\n",
    "         X_test.drop(['neighbourhood_cleansed', 'zipcode', 'property_type'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.401137412075702"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-fold\n",
    "\n",
    "for col in ['neighbourhood_cleansed', 'property_type', 'zipcode']:\n",
    "    tmp = pd.DataFrame({'feature': X_train[col], 'target': np.log1p(y_train)}).dropna()\n",
    "    global_mean = y_train.mean()\n",
    "    tst_mean = tmp.groupby('feature').target.mean()\n",
    "    tst_size = tmp.groupby('feature').target.size()\n",
    "    tst_encoding = (global_mean * C + tst_mean * tst_size) / (C + size)\n",
    "    \n",
    "    te = pd.Series(index=X_train.index)\n",
    "    kf = KFold(n_splits=5, shuffle=False, random_state=42)\n",
    "    for train_idx, test_idx in kf.split(tmp):\n",
    "        X_tr, X_val = tmp.iloc[train_idx], tmp.iloc[test_idx]\n",
    "        tmp_mean = X_tr.groupby('feature').target.mean()\n",
    "        tmp_size = X_tr.groupby('feature').target.size()\n",
    "        tmp_encoding = (global_mean * C + mean * size) / (C + size)\n",
    "        te.iloc[test_idx] = X_val['feature'].map(tmp_encoding).values\n",
    "        \n",
    "    X_train[col + '_te'] = te\n",
    "    X_test[col + '_te'] = X_test[col].map(tst_encoding).fillna(global_mean).values\n",
    "    \n",
    "# качество\n",
    "get_rate(X_train.drop(['neighbourhood_cleansed', 'zipcode', 'property_type'], axis=1),\n",
    "         X_test.drop(['neighbourhood_cleansed', 'zipcode', 'property_type'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# А как с кросс-валидацией? Чтобы не раздувать функцию кросс-валидации, все это надо оформить так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MeanEncoding(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Здесь мы делаем самый простой targetencoding - сложный и удобный пойдет в домашнее задание\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature, C=1.):\n",
    "        self.C = C\n",
    "        self.feature = feature\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        df = pd.DataFrame({'feature': X_train[self.feature], 'target': y_train}).dropna()\n",
    "        \n",
    "        self.global_mean = df.target.mean()\n",
    "        mean = df.groupby('feature').target.mean()\n",
    "        size = df.groupby('feature').target.size()\n",
    "        \n",
    "        self.encoding = (self.global_mean * self.C + mean * size) / (self.C + size)\n",
    "    \n",
    "    def transform(self, X_test):\n",
    "        \n",
    "        X_test[self.feature] = X_test[self.feature].map(self.encoding).fillna(self.global_mean).values\n",
    "        \n",
    "        \n",
    "        return X_test\n",
    "    \n",
    "    def fit_transform(self, X_train, y_train):\n",
    "        \n",
    "        df = pd.DataFrame({'feature': X_train[self.feature], 'target': y_train}).dropna()\n",
    "        \n",
    "        self.global_mean = df.target.mean()\n",
    "        mean = df.groupby('feature').target.mean()\n",
    "        size = df.groupby('feature').target.size()\n",
    "        self.encoding = (self.global_mean * self.C + mean * size) / (self.C + size)\n",
    "        \n",
    "        X_train[self.feature] = X_train[self.feature].map(self.encoding).fillna(self.global_mean).values\n",
    "        \n",
    "        return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.273938173670665, 1.4348108443583092)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor()\n",
    "\n",
    "cross_val(model, X.drop(['neighbourhood_cleansed', 'zipcode', 'property_type'], axis=1), y, CV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.215083350832344, 1.4521233440242987)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "te = MeanEncoding(feature = 'neighbourhood_cleansed', C=10)\n",
    "lgb = LGBMRegressor()\n",
    "\n",
    "model = make_pipeline(te, lgb)\n",
    "\n",
    "cross_val(model, X.drop(['zipcode', 'property_type'], axis=1), y, CV=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Для каких еще методов обработки данных лучше написать вот такой вот отдельный класс?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
